{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import sksurv\n",
    "from sksurv.util import Surv\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path[1:1] = [\"/home/ec2-user/SageMaker/GitHub Repos/cipy/cipy/\"]\n",
    "sys.path[2:2] = [\"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2\"]\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wqp_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path for Institutional Claims Data Path\n",
    "csv_path = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/01_data_preprocessing/preprocessed_datasets/\"\n",
    "\n",
    "# feature_file path for Numerical and Categorical Column Names \n",
    "feature_file = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/02_feat_sel_and_imp/institutional_claims/json_files/\"\n",
    "\n",
    "# path to save Categorical & Numerical Filtered Columns and Categorical & Numerical statistics for each claim_filing_indicator_code\n",
    "output_path = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/02_feat_sel_and_imp/institutional_claims/02_step/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the institutional claims dataset into inst_claims\n",
    "inst_claims = pd.read_csv(csv_path+\"ic_preprocessed_dataset_2021-06-06.csv\")\n",
    "\n",
    "inst_claims[\"event_flag\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_feat_path = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/02_feat_sel_and_imp/institutional_claims/03_step/ic_rfe_output.pickle\"\n",
    "\n",
    "with open(rfe_feat_path, \"rb\") as input_file:\n",
    "    rfe_feat_op = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final features as of 12th December, 2020.\n",
    "#please note that these may change once we finalize the hyper-parameters.\n",
    "\n",
    "medicaid_num_feat = [\"days_sum_quantity\", \n",
    "                     \"units_median_quantity\"]\n",
    "\n",
    "medicaid_cat_feat = [\"claim_creation_weekday\",\n",
    "                     \"claim_creation_dayofmonth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing outlier removal in response time values, encoding categorical data and then combining categorical and continuous features\n",
    "payer_name = \"Medicaid\"\n",
    "df = inst_claims[inst_claims[\"claim_filing_ind_code3\"]==payer_name].reset_index(drop=True)\n",
    "df = clip_right_tail2(df, 0.98)\n",
    "    \n",
    "df[\"response_time\"] = df[\"response_time\"].astype(\"float\")\n",
    "folds = get_folds(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical data\n",
    "from collections import defaultdict\n",
    "\n",
    "encoder_dict = defaultdict(LabelEncoder)\n",
    "cat_df = df[medicaid_cat_feat]\n",
    "cat_df = cat_df.astype(\"str\")\n",
    "cat_df = cat_df.apply(lambda x: encoder_dict[x.name].fit_transform(x))\n",
    "\n",
    "num_df = df[medicaid_num_feat]\n",
    "\n",
    "rsf_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "y = Surv.from_arrays(np.repeat(True, len(df)), df[\"response_time\"].values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the grid search parameters\n",
    "param_grid = {\"n_estimators\":[20, 50, 100, 200], \n",
    "              \"max_features\":[\"sqrt\", \"log2\"], \n",
    "              \"max_depth\":[5, 10, 15, 20],\n",
    "              \"min_samples_split\":[8, 10], \n",
    "              \"min_samples_leaf\":[4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch Object\n",
    "grid_search_cv = GridSearchCV(estimator=RandomSurvivalForest(oob_score=True), \n",
    "                              param_grid=param_grid, \n",
    "                              cv=folds,\n",
    "                              n_jobs=-1, \n",
    "                              verbose=10,\n",
    "                              return_train_score=True, \n",
    "                              refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the rsf algorithm on training data\n",
    "grid_search_cv.fit(rsf_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model parameters\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "results = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Test C-Index Parameters:\n",
    "mask = results[\"rank_test_c_index\"]=0\n",
    "print(\"Best Parameters: \", results.loc[mask, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([i for i in results.index], [i for i in results[\"mean_train_c_index\"].values], label=\"Train Mean C-Index\")\n",
    "plt.plot([i for i in results.index], [i for i in results[\"mean_test_c_index\"].values], label=\"Test Mean C-Index\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results[\"rank_test_c_index\"]=0\n",
    "params =  results.loc[mask, \"params\"]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pd.concat([cat_df, num_df], axis=1), open(\"TD_005010X223A2_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(rsf_df, open(\"ED_005010X223A2_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(encoder_dict, open(\"LE_005010X223A2_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(rsf, open(\"005010X223A2_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(results, open(\"RE_005010X223A2_\"+payer_name+\".pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wqp_kernel",
   "language": "python",
   "name": "wqp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
