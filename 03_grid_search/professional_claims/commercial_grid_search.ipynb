{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import sksurv\n",
    "from sksurv.util import Surv\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import integrated_brier_score\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path[1:1] = [\"/home/ec2-user/SageMaker/GitHub Repos/cipy/cipy/\"]\n",
    "sys.path[2:2] = [\"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2\"]\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wqp_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Institutional claims dataset\n",
    "ref_col= \"claim_filing_ind_code3\"\n",
    "\n",
    "# csv_path for Institutional Claims Data Path\n",
    "csv_path = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/01_data_preprocessing/preprocessed_datasets/\"\n",
    "\n",
    "prof_claims= pd.read_csv(csv_path+\"pc_preprocessed_dataset_2021-06-01.csv\")\n",
    "\n",
    "# Creating the event_flag - for survival analysis.\n",
    "prof_claims[\"event_flag\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_feat_path = \"/home/ec2-user/SageMaker/Users/SP056963/work_queue_prioritization_v2/02_feat_sel_and_imp/professional_claims/03_step/pc_rfe_output.pickle\"\n",
    "\n",
    "with open(rfe_feat_path, \"rb\") as input_file:\n",
    "    rfe_feat_op = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claim filing indicator specific continuous and categorical features\n",
    "commercial_num_feat = [\"days_taken_for_claim_filing\",\n",
    "                       \"total_claim_charge_amount\",\n",
    "                       \"count_line_items\"]\n",
    "\n",
    "commercial_cat_feat = [\"payer_state\",\n",
    "                       \"payer_city\",\n",
    "                       \"payer_name\",\n",
    "                       \"claim_creation_month\",\n",
    "                       \"claim_creation_quarter\",\n",
    "                       \"facility_name\",\n",
    "                       \"has_subgroup_or_policy_number\",\n",
    "                       \"claim_creation_weekday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing outlier removal in response time values, encoding categorical data and then combining categorical and continuous features\n",
    "payer_name = \"Commercial Insurance Co.\"\n",
    "\n",
    "df = prof_claims[prof_claims[\"claim_filing_ind_code3\"]==payer_name].reset_index(drop=True)\n",
    "df = clip_right_tail2(df, 0.99)\n",
    "    \n",
    "df[\"response_time\"] = df[\"response_time\"].astype(\"float\")\n",
    "folds = get_folds(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling grid_search meth# Encoding the categorical data\n",
    "from collections import defaultdict\n",
    "\n",
    "encoder_dict = defaultdict(LabelEncoder)\n",
    "cat_df = df[commercial_cat_feat]\n",
    "cat_df = cat_df.astype(\"str\")\n",
    "cat_df = cat_df.apply(lambda x: encoder_dict[x.name].fit_transform(x))\n",
    "\n",
    "num_df = df[commercial_num_feat]\n",
    "\n",
    "rsf_df = pd.concat([num_df, cat_df], axis=1)\n",
    "\n",
    "y = Surv.from_arrays(np.repeat(True, len(df)), df[\"response_time\"].values)    od\n",
    "c_index_values_df = grid_search(df, rsf_df, grid_search_params, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the grid search parameters\n",
    "param_grid = {\"n_estimators\":[20, 50, 100, 200], \n",
    "              \"max_features\":[\"sqrt\", \"log2\"], \n",
    "              \"max_depth\":[5, 10, 15, 20],\n",
    "              \"min_samples_split\":[8, 10], \n",
    "              \"min_samples_leaf\":[4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch Object\n",
    "grid_search_cv = GridSearchCV(estimator=RandomSurvivalForest(oob_score=True), \n",
    "                              param_grid=param_grid, \n",
    "                              cv=folds,\n",
    "                              n_jobs=-1, \n",
    "                              verbose=10,\n",
    "                              return_train_score=True, \n",
    "                              refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the rsf algorithm on training data\n",
    "grid_search_cv.fit(rsf_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Model parameters\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "results = pd.DataFrame(grid_search_cv.cv_results_)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Test C-Index Parameters:\n",
    "mask = results[\"rank_test_c_index\"]=0\n",
    "print(\"Best Parameters: \", results.loc[mask, \"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([i for i in results.index], [i for i in results[\"mean_train_c_index\"].values], label=\"Train Mean C-Index\")\n",
    "plt.plot([i for i in results.index], [i for i in results[\"mean_test_c_index\"].values], label=\"Test Mean C-Index\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results[\"rank_test_c_index\"]=0\n",
    "params =  results.loc[mask, \"params\"]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pd.concat([cat_df, num_df], axis=1), open(\"TD_005010X222A1_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(rsf_df, open(\"ED_005010X222A1_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(encoder_dict, open(\"LE_005010X222A1_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(rsf, open(\"005010X222A1_\"+payer_name+\".pickle\", \"wb\"))\n",
    "pickle.dump(results, open(\"RE_005010X222A1_\"+payer_name+\".pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
